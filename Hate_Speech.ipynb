{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dlPlbydhm8M",
        "outputId": "9cf9e11d-0e26-44df-b81c-87ace334a7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing\n"
          ]
        }
      ],
      "source": [
        "print(\"Testing\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hate speech is generally a task of sentiment classi\n",
        "# Can be achived by traing it by data\n",
        ""
      ],
      "metadata": {
        "id": "wTMItoGZilGo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HATE SPEECH DETECTION MODEL"
      ],
      "metadata": {
        "id": "o9iImimyjL9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HORJRilujJwh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv('train.csv')\n",
        "print(\"Training Set :\"%train.columns,train.shape,len(train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6TkXxVBjSHx",
        "outputId": "10289e53-4757-4d1e-cf11-f5b45fa0f68b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set : (31962, 3) 31962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.read_csv('test.csv')\n",
        "print(\"Test Set :\"%test.columns,test.shape,len(test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lhY1lAejdPr",
        "outputId": "54f563d6-e32f-4ec9-d491-3653a760da00"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set : (17197, 2) 17197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(df,text_feild):\n",
        "  df[text_feild]=df[text_feild].str.lower()\n",
        "  df[text_feild] = df[text_feild].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))\n",
        "  return df\n",
        "test_clean = clean_text(test, \"tweet\")\n",
        "train_clean = clean_text(train, \"tweet\")\n",
        "\n",
        "#can use oversampling or down sampling\n",
        "# (@[A-Za-z0-9] matches twitter handle\n",
        "#([^0-9A-Za-z \\t]): Matches any character that is not a digit, letter, space, or tab. This effectively removes special characters and punctuation.\n",
        "#(\\w+:\\/\\/\\S+): Matches URLs starting with a word followed by :// and then any non-whitespace characters.\n",
        "#^rt: Matches the string \"rt\" at the beginning of the text, which indicates a retweet in Twitter.\n",
        "#http.+?: Matches any URL starting with \"http\".$"
      ],
      "metadata": {
        "id": "6fl8tkpvkKo9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps which are followed below for sampling\n",
        "Import Resample: Use resample from sklearn.utils for upsampling.\n",
        "Separate Majority Class: Create train_majority with rows where label == 0.\n",
        "Separate Minority Class: Create train_minority with rows where label == 1.\n",
        "Upsample Minority: Use resample to increase train_minority to the size of train_majority.\n",
        "Combine Classes: Concatenate train_minority_upsampled and train_majority to form train_upsampled.\n",
        "Verify Balance: Check the distribution of labels in train_upsampled using value_counts()."
      ],
      "metadata": {
        "id": "C9aElPvdpjmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "train_majority = train_clean[train_clean.label==0]\n",
        "train_minority = train_clean[train_clean.label==1]\n",
        "train_minority_upsampled = resample(train_minority,\n",
        "                                 replace=True,\n",
        "                                 n_samples=len(train_majority),\n",
        "                                 random_state=123)\n",
        "train_upsampled = pd.concat([train_minority_upsampled, train_majority])\n",
        "train_upsampled['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw7qbp0blUlm",
        "outputId": "773ae63d-98b5-4712-cbe1-455236ce1488"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    29720\n",
              "0    29720\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEPS / BASIC EXPLAINATION FOR THE FOLLOWING CODE\n",
        "Certainly! Here is the code explained point by point in one line each:\n",
        "\n",
        "1. **Import TfidfVectorizer**: `from sklearn.feature_extraction.text import TfidfVectorizer` - Import for creating TF-IDF features.\n",
        "2. **Import Pipeline**: `from sklearn.pipeline import Pipeline` - Import to create a machine learning pipeline.\n",
        "3. **Import CountVectorizer**: `from sklearn.feature_extraction.text import CountVectorizer` - Import for converting text to a matrix of token counts.\n",
        "4. **Import TfidfTransformer**: `from sklearn.feature_extraction.text import TfidfTransformer` - Import for transforming token counts to TF-IDF representation.\n",
        "5. **Import SGDClassifier**: `from sklearn.linear_model import SGDClassifier` - Import for linear classifier optimized by stochastic gradient descent.\n",
        "6. **Define Pipeline**: `pipeline_sgd = Pipeline([ ... ])` - Create a pipeline named `pipeline_sgd` that sequentially applies text transformations and a classifier.\n",
        "7. **Step 1 - CountVectorizer**: `('vect', CountVectorizer())` - First step, tokenize text and convert to token count matrix.\n",
        "8. **Step 2 - TfidfTransformer**: `('tfidf', TfidfTransformer())` - Second step, transform token counts to TF-IDF features.\n",
        "9. **Step 3 - SGDClassifier**: `('nb', SGDClassifier())` - Third step, apply SGDClassifier to the TF-IDF features for training a linear model."
      ],
      "metadata": {
        "id": "HCjhGGznxYSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "pipeline_sgd = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf',  TfidfTransformer()),\n",
        "    ('nb', SGDClassifier()),])"
      ],
      "metadata": {
        "id": "5saYvI4xpRN1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_upsampled['tweet'],\n",
        "                                                    train_upsampled['label'],random_state = 0)"
      ],
      "metadata": {
        "id": "zyBxpeDaxojc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline_sgd.fit(X_train, y_train)\n",
        "y_predict = model.predict(X_test)\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb0odWT5x_yU",
        "outputId": "7d66b55c-ad03-47e3-fdd5-e88fe6e58cc5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.969729297239632"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHhGj4UXyi8z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}